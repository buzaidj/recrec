\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Recipe Recommendations for any home chef}
\author{jjb422, mia27, gtd35 }
\date{October 2021}

\begin{document}

\maketitle 


\section{Introduction}

The problem we want to solve is recommending good recipes to people based on their recommendations. We want to create models to recommend recipes based on past enjoyed and preferences. For each meal of the day (breakfast, lunch, dinner, and dessert) a user can input recipes they've made in the past (ex: chicken Alfredo) as well as their preferences over clean up, food cost, and time spent cooking. We are also planning on allowing a user can also input their family size, portion size, and calorie goals.

Different people have different recipe preferences depending on the amount of time they want to spend on a recipe, what kind of food they like, and more. A naive approach to this problem is just to ask the user for their preferences and choose the recipe based on these preferences given by some algorithm. In this case we aren't really "learning" or doing anything intelligent. It also may not be accurate. It is hard to directly ask the user for these preferences as it would be somewhat boring and may not actually reflect their true preferences. For instance, they might like something they don't know they like as of yet. 

Thus, we want to use a Tinder-like approach, where people can view recipes one at a time and swipe on if they like them or not. This lets our model be a little simpler (people like a recipe or don't). A recipe will have a photo of it, with data on the time it takes to cook, an estimate on cleanup time (we can determine using an algorithm, unless provided in the recipe), how many servings it makes, calories per portion, allergens, etc.


\section{Approach}

    \subsection{Gathering Recipe Data}

    \begin{itemize}
        \item We will need to collect thousands of recipes and store them in a tree like structure, with different trees for different meals.
        \item We need to categorize recipes for each meal, and features them by taste profiles, calories, serving sizes, time spent, clean up, and monetary food cost. We will determine how best to categorize these into features. For instance, time can be a real valued variable since it is almost always included in recipes, but clean up may be a binary because we will have to determine it from other fields.
        \item We need to find some monetary cost data for different foods.
        \item We will need to download preexisting databases for recipes and food costs or scrape this data from the web. We cannot do this manually for we don't have the time.
        \item We will need to develop certain fields that do not always exist. For example recipes using only one pan don't include a clean up time, but we want to mark them as having low clean up time.
    \end{itemize}
    
    \subsection{Gathering User Data}
    
    We have two approaches for gathering user data. The first is naively asking them for their preferences for each of the features.
    
    The second is to continue gathering data interspersed with recommendations. We can present the user a random recipe from our collection of thousands of recipes and see if they like that recipe or not.
    
    \subsection{Models}
    
    We plan on using several models in our project with varying dependence on user input over time. 
    
    (1) Our first naive approach is to continually ask the user for their preferences as a vector over all features and then just find the best recipe that fits their current preferences out of the recipes to recommend. We want to use a K-nearest neighbors approach for this to generate K recipe recommendations out the K nearest recipes. We can remove these recipes and continue for another K recipes and so forth.
    
    (2)  A smarter idea is to only ask the user for their preferences in the beginning and detect small changes in their preferences by randomly getting new data every now and then to update the model. In this case, recommendations are interspersed with new data points. To the user recommendation's and new data points look the same, except a recommendation has come from our algorithm and the users response will determine if we made a correct prediction, and the new points are recipes.  This approach is known as online learning. In this approach we incorporate new data points into an existing model. We want to predict for unseen recipes if the user likes them or not. We've learned previously that perceptron is good for this purpose. We also want to use a neutral network with SGD to solve it, only updating every 20-30 observations instead of retraining with every new observation to save computation.

    \subsection{Overfitting (\textit{The Chicken Parm Problem})}
    
    One problem we saw immediately with any solution to this model is how easy it is to over-fit for our data and recommend the same recipe over and over. Different models have ways to control for this. We also plan to remove duplicates of the same recipe for the same exact serving size. For instance, there are so many chicken parm recipes out there that serve four, but we want to remove duplicates and only pick the highest rated of these.
    
\section{Evaluation}
    Every time a recipe is recommended, the user swipes on if they like that recipe or not. If they don't like that recipe we have an error / bad recommendation, and if they like that recipe we have a success. We can evaluate different models based on this error criterion. Our error equals number of bad recommendations over total recommendations, and we would like to minimize this metric for some given users. We will have some of our friends try our app and we can record their responses.
\end{document}
